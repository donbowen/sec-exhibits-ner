{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3117a5e-7c66-4b0a-8c40-e4ed7cc69b92",
   "metadata": {},
   "source": [
    "## I. Setup, Installations, and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ad790-8001-4fe0-b389-3b8c1883ed24",
   "metadata": {},
   "source": [
    "#### (a) Installations\n",
    "\n",
    "Run these if not on your computer already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5756d57-cb7b-4d27-850b-022e162183ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install spacy\n",
    "# ! pip install nltk\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "# ! pip install svgling\n",
    "# ! python -m pip install textacy\n",
    "# ! pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c90a9-2148-41a3-84f4-0884b30b2b08",
   "metadata": {},
   "source": [
    "#### (b) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264d63d0-c461-495c-a103-ea6853b3f9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4014075000243ea8de9259a8eb2057c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 18:09:57 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-03-29 18:09:58 INFO: File exists: /Users/mikerich/stanza_resources/en/default.zip\n",
      "2023-03-29 18:10:02 INFO: Finished downloading models and saved to /Users/mikerich/stanza_resources.\n",
      "2023-03-29 18:10:02 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:02 INFO: Using device: cpu\n",
      "2023-03-29 18:10:02 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:02 INFO: Loading: pos\n",
      "2023-03-29 18:10:02 INFO: Loading: lemma\n",
      "2023-03-29 18:10:02 INFO: Loading: constituency\n",
      "2023-03-29 18:10:02 INFO: Loading: depparse\n",
      "2023-03-29 18:10:03 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:03 INFO: Loading: ner\n",
      "2023-03-29 18:10:03 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import torch;\n",
    "import stanza; stanza.download('en') # This downloads the English models for the neural pipelin\n",
    "nlp = stanza.Pipeline('en',download_method=None) # This sets up a default neural pipeline in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44d592f-aa51-45f5-a333-6a1b2efbde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from __future__ import unicode_literals\n",
    "import spacy,en_core_web_sm\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348a921-505c-40c4-b626-078e9ee0aed4",
   "metadata": {},
   "source": [
    "#### (c) Downloads\n",
    "\n",
    "Run these if not on your computer already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1fc49d-193f-4cc5-9a98-6629b68e002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/mikerich/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mikerich/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/mikerich/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mikerich/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/mikerich/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260beeb-2c7a-49e2-971d-815e177dd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('words')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b811b7-e9ee-4459-baa1-2ed4f28d89bc",
   "metadata": {},
   "source": [
    "## II. Defined Functions Used In Program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576a592-0448-4647-8378-47264ac189e0",
   "metadata": {},
   "source": [
    "#### (a) Named Entity Recognizer Function\n",
    "**Input:** A sentence <br> \n",
    "**Output:** A dictionary in the form of: <br>\n",
    "&emsp;**{'entities':** [list of named entity recognizers of that sentence], **'verbs':** [list of the verbs], **'subjects':** [list of the subjects]**, 'subj_verb_linkages',** [root subject verb linkage array]**}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868da488-9b31-41b5-b60a-7047cb03c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(sentence): \n",
    "    \n",
    "    entities = []\n",
    "    verbs = []\n",
    "    subjects = []\n",
    "    subj_verb_linkages = []\n",
    "    \n",
    "    #Find the entities in the sentence\n",
    "    words  = nltk.word_tokenize(sentence)        # break down the sentence into words\n",
    "    tagged = nltk.pos_tag(words)                 # tag the words with Part of Speech \n",
    "    chunks = nltk.ne_chunk(tagged, binary=False) # binary = False named entities are classified (i.e PERSON, ORGANIZATION)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'):              # hasattr(obj, key) -- checking if chunks have a label or not \n",
    "            entities.append(' '.join(c[0] for c in chunk)) # append entities to array\n",
    "    \n",
    "    \n",
    "    #Find the verbs/subjects in the sentence\n",
    "    nlp = spacy.load(\"en_core_web_sm\")           # load in the spacy model\n",
    "    doc = nlp(sentence)                          # create spacy doc object\n",
    "    \n",
    "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]     # traverse thru the tokens, find the verbs\n",
    "    subjects = [token.text for token in doc if token.dep_ == \"nsubj\"]  # traverse thru the tokens, find the subjects\n",
    "    \n",
    "    \n",
    "    #Find the Root Subject-verb linkages in the sentences using stanza\n",
    "    nlp = stanza.Pipeline('en', download_method=None)    # this sets up a default neural pipeline in English\n",
    "    doc = nlp(sentence)\n",
    "     \n",
    "    root_verb = None\n",
    "    subject = None\n",
    "    \n",
    "    for word in doc.sentences[0].words:    # for each word in the sentence\n",
    "        if word.deprel == 'root':          # if a word is the root, its dependency relation label is 'root'. thus if this is true, the curr word = root word\n",
    "\n",
    "            root_verb = word.text          # save the root verb  \n",
    "            root_id = word.id              # get the words id \n",
    "            \n",
    "            for w in doc.sentences[0].words:                      # loop over words in the sentence\n",
    "                if w.head == root_id and w.deprel == 'nsubj':     # if words head attribute = root_id, then its a a direct dependent of the root (is a child of the root)\n",
    "                    subject = w.text \n",
    "                \n",
    "    subj_verb_linkages = [subject, root_verb]   # subj_verb linkages array \n",
    "    \n",
    "        \n",
    "    return {'entities':entities, \n",
    "            'verbs':verbs,\n",
    "            'subjects':subjects,\n",
    "            'subj_verb_linkages':subj_verb_linkages} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586829ef-3a1a-4949-afd4-485d76de01ae",
   "metadata": {},
   "source": [
    "#### (b) Filename Traversal Function\n",
    "**Input:** A Filename **(i.e /inputs/ex10.txt)** <br>\n",
    "**Output:** A dict of dicts: <br>\n",
    "&emsp;&emsp;&emsp;&emsp;**{sentence: {sentence_level_outputs}}** <br>\n",
    "&emsp;&emsp;where sentence_level_outputs <br>\n",
    "&emsp;&emsp;&emsp;&emsp;**{'analysis type/function' : output thereof}**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0227a2ce-adbb-4966-a2cf-3ab7d966f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_trawl(filename):\n",
    "\n",
    "    file_output = {}\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        raw = BeautifulSoup(fp.read(), 'html.parser').get_text()\n",
    "        raw_sentences = nltk.sent_tokenize(raw)\n",
    "    \n",
    "    for sentence in raw_sentences:\n",
    "        \n",
    "        # put all output of this sentence here \n",
    "        # key=analysis type/function, value=output thereof\n",
    "        sentence_level_outputs = {} \n",
    "        \n",
    "        # use ner function  \n",
    "        sentence_level_outputs.update(ner(sentence))\n",
    "        \n",
    "        # any other output we want to add that doesn't rely on the ner tokenization\n",
    "        # should be done here\n",
    "        # to show that the plumbing works correctly, let's add variable 2:\n",
    "        sentence_level_outputs['random_num'] = np.random.uniform()\n",
    "        \n",
    "        # Add to output dictionary\n",
    "        file_output.update({sentence:sentence_level_outputs})\n",
    "        \n",
    "    return file_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269663da-29a9-423b-88a3-3be0d5d01c29",
   "metadata": {},
   "source": [
    "## III. Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663b4559-824d-4063-93b2-8a84e9cc307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]2023-03-29 18:10:19 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:19 INFO: Using device: cpu\n",
      "2023-03-29 18:10:19 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:19 INFO: Loading: pos\n",
      "2023-03-29 18:10:19 INFO: Loading: lemma\n",
      "2023-03-29 18:10:19 INFO: Loading: constituency\n",
      "2023-03-29 18:10:20 INFO: Loading: depparse\n",
      "2023-03-29 18:10:20 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:20 INFO: Loading: ner\n",
      "2023-03-29 18:10:21 INFO: Done loading processors!\n",
      "2023-03-29 18:10:27 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:27 INFO: Using device: cpu\n",
      "2023-03-29 18:10:27 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:27 INFO: Loading: pos\n",
      "2023-03-29 18:10:27 INFO: Loading: lemma\n",
      "2023-03-29 18:10:27 INFO: Loading: constituency\n",
      "2023-03-29 18:10:27 INFO: Loading: depparse\n",
      "2023-03-29 18:10:28 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:28 INFO: Loading: ner\n",
      "2023-03-29 18:10:28 INFO: Done loading processors!\n",
      "2023-03-29 18:10:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:31 INFO: Using device: cpu\n",
      "2023-03-29 18:10:31 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:31 INFO: Loading: pos\n",
      "2023-03-29 18:10:31 INFO: Loading: lemma\n",
      "2023-03-29 18:10:31 INFO: Loading: constituency\n",
      "2023-03-29 18:10:32 INFO: Loading: depparse\n",
      "2023-03-29 18:10:32 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:32 INFO: Loading: ner\n",
      "2023-03-29 18:10:33 INFO: Done loading processors!\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "2023-03-29 18:10:34 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:34 INFO: Using device: cpu\n",
      "2023-03-29 18:10:34 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:34 INFO: Loading: pos\n",
      "2023-03-29 18:10:34 INFO: Loading: lemma\n",
      "2023-03-29 18:10:34 INFO: Loading: constituency\n",
      "2023-03-29 18:10:34 INFO: Loading: depparse\n",
      "2023-03-29 18:10:35 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:35 INFO: Loading: ner\n",
      "2023-03-29 18:10:36 INFO: Done loading processors!\n",
      "2023-03-29 18:10:36 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:36 INFO: Using device: cpu\n",
      "2023-03-29 18:10:36 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:36 INFO: Loading: pos\n",
      "2023-03-29 18:10:37 INFO: Loading: lemma\n",
      "2023-03-29 18:10:37 INFO: Loading: constituency\n",
      "2023-03-29 18:10:37 INFO: Loading: depparse\n",
      "2023-03-29 18:10:37 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:38 INFO: Loading: ner\n",
      "2023-03-29 18:10:38 INFO: Done loading processors!\n",
      "2023-03-29 18:10:40 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:40 INFO: Using device: cpu\n",
      "2023-03-29 18:10:40 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:40 INFO: Loading: pos\n",
      "2023-03-29 18:10:40 INFO: Loading: lemma\n",
      "2023-03-29 18:10:40 INFO: Loading: constituency\n",
      "2023-03-29 18:10:41 INFO: Loading: depparse\n",
      "2023-03-29 18:10:41 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:41 INFO: Loading: ner\n",
      "2023-03-29 18:10:42 INFO: Done loading processors!\n",
      "2023-03-29 18:10:43 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:43 INFO: Using device: cpu\n",
      "2023-03-29 18:10:43 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:43 INFO: Loading: pos\n",
      "2023-03-29 18:10:43 INFO: Loading: lemma\n",
      "2023-03-29 18:10:43 INFO: Loading: constituency\n",
      "2023-03-29 18:10:44 INFO: Loading: depparse\n",
      "2023-03-29 18:10:44 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:44 INFO: Loading: ner\n",
      "2023-03-29 18:10:45 INFO: Done loading processors!\n",
      "2023-03-29 18:10:48 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:48 INFO: Using device: cpu\n",
      "2023-03-29 18:10:48 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:48 INFO: Loading: pos\n",
      "2023-03-29 18:10:49 INFO: Loading: lemma\n",
      "2023-03-29 18:10:49 INFO: Loading: constituency\n",
      "2023-03-29 18:10:49 INFO: Loading: depparse\n",
      "2023-03-29 18:10:49 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:49 INFO: Loading: ner\n",
      "2023-03-29 18:10:50 INFO: Done loading processors!\n",
      "2023-03-29 18:10:51 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:51 INFO: Using device: cpu\n",
      "2023-03-29 18:10:51 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:51 INFO: Loading: pos\n",
      "2023-03-29 18:10:51 INFO: Loading: lemma\n",
      "2023-03-29 18:10:51 INFO: Loading: constituency\n",
      "2023-03-29 18:10:52 INFO: Loading: depparse\n",
      "2023-03-29 18:10:52 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:52 INFO: Loading: ner\n",
      "2023-03-29 18:10:52 INFO: Done loading processors!\n",
      "2023-03-29 18:10:53 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:53 INFO: Using device: cpu\n",
      "2023-03-29 18:10:53 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:53 INFO: Loading: pos\n",
      "2023-03-29 18:10:54 INFO: Loading: lemma\n",
      "2023-03-29 18:10:54 INFO: Loading: constituency\n",
      "2023-03-29 18:10:54 INFO: Loading: depparse\n",
      "2023-03-29 18:10:55 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:55 INFO: Loading: ner\n",
      "2023-03-29 18:10:55 INFO: Done loading processors!\n",
      "2023-03-29 18:10:57 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:10:57 INFO: Using device: cpu\n",
      "2023-03-29 18:10:57 INFO: Loading: tokenize\n",
      "2023-03-29 18:10:57 INFO: Loading: pos\n",
      "2023-03-29 18:10:57 INFO: Loading: lemma\n",
      "2023-03-29 18:10:57 INFO: Loading: constituency\n",
      "2023-03-29 18:10:57 INFO: Loading: depparse\n",
      "2023-03-29 18:10:58 INFO: Loading: sentiment\n",
      "2023-03-29 18:10:58 INFO: Loading: ner\n",
      "2023-03-29 18:10:59 INFO: Done loading processors!\n",
      "2023-03-29 18:11:00 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:00 INFO: Using device: cpu\n",
      "2023-03-29 18:11:00 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:00 INFO: Loading: pos\n",
      "2023-03-29 18:11:01 INFO: Loading: lemma\n",
      "2023-03-29 18:11:02 INFO: Loading: constituency\n",
      "2023-03-29 18:11:02 INFO: Loading: depparse\n",
      "2023-03-29 18:11:03 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:03 INFO: Loading: ner\n",
      "2023-03-29 18:11:03 INFO: Done loading processors!\n",
      "2023-03-29 18:11:08 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:08 INFO: Using device: cpu\n",
      "2023-03-29 18:11:08 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:08 INFO: Loading: pos\n",
      "2023-03-29 18:11:09 INFO: Loading: lemma\n",
      "2023-03-29 18:11:09 INFO: Loading: constituency\n",
      "2023-03-29 18:11:09 INFO: Loading: depparse\n",
      "2023-03-29 18:11:09 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:09 INFO: Loading: ner\n",
      "2023-03-29 18:11:10 INFO: Done loading processors!\n",
      "2023-03-29 18:11:11 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:11 INFO: Using device: cpu\n",
      "2023-03-29 18:11:11 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:11 INFO: Loading: pos\n",
      "2023-03-29 18:11:11 INFO: Loading: lemma\n",
      "2023-03-29 18:11:12 INFO: Loading: constituency\n",
      "2023-03-29 18:11:12 INFO: Loading: depparse\n",
      "2023-03-29 18:11:12 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:12 INFO: Loading: ner\n",
      "2023-03-29 18:11:13 INFO: Done loading processors!\n",
      "2023-03-29 18:11:15 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:15 INFO: Using device: cpu\n",
      "2023-03-29 18:11:15 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:15 INFO: Loading: pos\n",
      "2023-03-29 18:11:15 INFO: Loading: lemma\n",
      "2023-03-29 18:11:15 INFO: Loading: constituency\n",
      "2023-03-29 18:11:15 INFO: Loading: depparse\n",
      "2023-03-29 18:11:16 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:16 INFO: Loading: ner\n",
      "2023-03-29 18:11:17 INFO: Done loading processors!\n",
      "2023-03-29 18:11:18 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:18 INFO: Using device: cpu\n",
      "2023-03-29 18:11:18 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:18 INFO: Loading: pos\n",
      "2023-03-29 18:11:19 INFO: Loading: lemma\n",
      "2023-03-29 18:11:19 INFO: Loading: constituency\n",
      "2023-03-29 18:11:20 INFO: Loading: depparse\n",
      "2023-03-29 18:11:20 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:21 INFO: Loading: ner\n",
      "2023-03-29 18:11:22 INFO: Done loading processors!\n",
      "2023-03-29 18:11:27 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:27 INFO: Using device: cpu\n",
      "2023-03-29 18:11:27 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:27 INFO: Loading: pos\n",
      "2023-03-29 18:11:28 INFO: Loading: lemma\n",
      "2023-03-29 18:11:28 INFO: Loading: constituency\n",
      "2023-03-29 18:11:28 INFO: Loading: depparse\n",
      "2023-03-29 18:11:29 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:29 INFO: Loading: ner\n",
      "2023-03-29 18:11:30 INFO: Done loading processors!\n",
      "2023-03-29 18:11:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:31 INFO: Using device: cpu\n",
      "2023-03-29 18:11:31 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:31 INFO: Loading: pos\n",
      "2023-03-29 18:11:31 INFO: Loading: lemma\n",
      "2023-03-29 18:11:31 INFO: Loading: constituency\n",
      "2023-03-29 18:11:32 INFO: Loading: depparse\n",
      "2023-03-29 18:11:32 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:32 INFO: Loading: ner\n",
      "2023-03-29 18:11:33 INFO: Done loading processors!\n",
      "2023-03-29 18:11:34 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:34 INFO: Using device: cpu\n",
      "2023-03-29 18:11:34 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:34 INFO: Loading: pos\n",
      "2023-03-29 18:11:34 INFO: Loading: lemma\n",
      "2023-03-29 18:11:34 INFO: Loading: constituency\n",
      "2023-03-29 18:11:35 INFO: Loading: depparse\n",
      "2023-03-29 18:11:35 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:35 INFO: Loading: ner\n",
      "2023-03-29 18:11:36 INFO: Done loading processors!\n",
      "2023-03-29 18:11:38 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:38 INFO: Using device: cpu\n",
      "2023-03-29 18:11:38 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:38 INFO: Loading: pos\n",
      "2023-03-29 18:11:38 INFO: Loading: lemma\n",
      "2023-03-29 18:11:38 INFO: Loading: constituency\n",
      "2023-03-29 18:11:39 INFO: Loading: depparse\n",
      "2023-03-29 18:11:40 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:40 INFO: Loading: ner\n",
      "2023-03-29 18:11:41 INFO: Done loading processors!\n",
      "2023-03-29 18:11:42 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:42 INFO: Using device: cpu\n",
      "2023-03-29 18:11:42 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:42 INFO: Loading: pos\n",
      "2023-03-29 18:11:43 INFO: Loading: lemma\n",
      "2023-03-29 18:11:43 INFO: Loading: constituency\n",
      "2023-03-29 18:11:44 INFO: Loading: depparse\n",
      "2023-03-29 18:11:44 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:45 INFO: Loading: ner\n",
      "2023-03-29 18:11:46 INFO: Done loading processors!\n",
      "2023-03-29 18:11:49 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:49 INFO: Using device: cpu\n",
      "2023-03-29 18:11:49 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:49 INFO: Loading: pos\n",
      "2023-03-29 18:11:49 INFO: Loading: lemma\n",
      "2023-03-29 18:11:49 INFO: Loading: constituency\n",
      "2023-03-29 18:11:50 INFO: Loading: depparse\n",
      "2023-03-29 18:11:50 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:51 INFO: Loading: ner\n",
      "2023-03-29 18:11:51 INFO: Done loading processors!\n",
      "2023-03-29 18:11:53 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:53 INFO: Using device: cpu\n",
      "2023-03-29 18:11:53 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:53 INFO: Loading: pos\n",
      "2023-03-29 18:11:53 INFO: Loading: lemma\n",
      "2023-03-29 18:11:53 INFO: Loading: constituency\n",
      "2023-03-29 18:11:54 INFO: Loading: depparse\n",
      "2023-03-29 18:11:54 INFO: Loading: sentiment\n",
      "2023-03-29 18:11:54 INFO: Loading: ner\n",
      "2023-03-29 18:11:55 INFO: Done loading processors!\n",
      "2023-03-29 18:11:59 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:11:59 INFO: Using device: cpu\n",
      "2023-03-29 18:11:59 INFO: Loading: tokenize\n",
      "2023-03-29 18:11:59 INFO: Loading: pos\n",
      "2023-03-29 18:11:59 INFO: Loading: lemma\n",
      "2023-03-29 18:11:59 INFO: Loading: constituency\n",
      "2023-03-29 18:11:59 INFO: Loading: depparse\n",
      "2023-03-29 18:11:59 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:00 INFO: Loading: ner\n",
      "2023-03-29 18:12:00 INFO: Done loading processors!\n",
      "2023-03-29 18:12:02 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:02 INFO: Using device: cpu\n",
      "2023-03-29 18:12:02 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:02 INFO: Loading: pos\n",
      "2023-03-29 18:12:02 INFO: Loading: lemma\n",
      "2023-03-29 18:12:02 INFO: Loading: constituency\n",
      "2023-03-29 18:12:03 INFO: Loading: depparse\n",
      "2023-03-29 18:12:03 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:03 INFO: Loading: ner\n",
      "2023-03-29 18:12:04 INFO: Done loading processors!\n",
      "2023-03-29 18:12:07 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:07 INFO: Using device: cpu\n",
      "2023-03-29 18:12:07 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:07 INFO: Loading: pos\n",
      "2023-03-29 18:12:07 INFO: Loading: lemma\n",
      "2023-03-29 18:12:09 INFO: Loading: constituency\n",
      "2023-03-29 18:12:09 INFO: Loading: depparse\n",
      "2023-03-29 18:12:10 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:10 INFO: Loading: ner\n",
      "2023-03-29 18:12:10 INFO: Done loading processors!\n",
      "2023-03-29 18:12:12 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:12 INFO: Using device: cpu\n",
      "2023-03-29 18:12:12 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:12 INFO: Loading: pos\n",
      "2023-03-29 18:12:12 INFO: Loading: lemma\n",
      "2023-03-29 18:12:12 INFO: Loading: constituency\n",
      "2023-03-29 18:12:13 INFO: Loading: depparse\n",
      "2023-03-29 18:12:13 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:13 INFO: Loading: ner\n",
      "2023-03-29 18:12:13 INFO: Done loading processors!\n",
      "2023-03-29 18:12:15 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:15 INFO: Using device: cpu\n",
      "2023-03-29 18:12:15 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:15 INFO: Loading: pos\n",
      "2023-03-29 18:12:15 INFO: Loading: lemma\n",
      "2023-03-29 18:12:15 INFO: Loading: constituency\n",
      "2023-03-29 18:12:15 INFO: Loading: depparse\n",
      "2023-03-29 18:12:15 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:16 INFO: Loading: ner\n",
      "2023-03-29 18:12:16 INFO: Done loading processors!\n",
      "2023-03-29 18:12:18 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:18 INFO: Using device: cpu\n",
      "2023-03-29 18:12:18 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:18 INFO: Loading: pos\n",
      "2023-03-29 18:12:18 INFO: Loading: lemma\n",
      "2023-03-29 18:12:18 INFO: Loading: constituency\n",
      "2023-03-29 18:12:19 INFO: Loading: depparse\n",
      "2023-03-29 18:12:19 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:20 INFO: Loading: ner\n",
      "2023-03-29 18:12:20 INFO: Done loading processors!\n",
      "2023-03-29 18:12:22 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:22 INFO: Using device: cpu\n",
      "2023-03-29 18:12:22 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:22 INFO: Loading: pos\n",
      "2023-03-29 18:12:22 INFO: Loading: lemma\n",
      "2023-03-29 18:12:23 INFO: Loading: constituency\n",
      "2023-03-29 18:12:23 INFO: Loading: depparse\n",
      "2023-03-29 18:12:24 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:24 INFO: Loading: ner\n",
      "2023-03-29 18:12:25 INFO: Done loading processors!\n",
      "2023-03-29 18:12:28 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:28 INFO: Using device: cpu\n",
      "2023-03-29 18:12:28 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:28 INFO: Loading: pos\n",
      "2023-03-29 18:12:28 INFO: Loading: lemma\n",
      "2023-03-29 18:12:28 INFO: Loading: constituency\n",
      "2023-03-29 18:12:29 INFO: Loading: depparse\n",
      "2023-03-29 18:12:29 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:29 INFO: Loading: ner\n",
      "2023-03-29 18:12:30 INFO: Done loading processors!\n",
      "2023-03-29 18:12:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:31 INFO: Using device: cpu\n",
      "2023-03-29 18:12:31 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:31 INFO: Loading: pos\n",
      "2023-03-29 18:12:31 INFO: Loading: lemma\n",
      "2023-03-29 18:12:31 INFO: Loading: constituency\n",
      "2023-03-29 18:12:31 INFO: Loading: depparse\n",
      "2023-03-29 18:12:32 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:32 INFO: Loading: ner\n",
      "2023-03-29 18:12:32 INFO: Done loading processors!\n",
      "2023-03-29 18:12:34 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:34 INFO: Using device: cpu\n",
      "2023-03-29 18:12:34 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:34 INFO: Loading: pos\n",
      "2023-03-29 18:12:34 INFO: Loading: lemma\n",
      "2023-03-29 18:12:34 INFO: Loading: constituency\n",
      "2023-03-29 18:12:34 INFO: Loading: depparse\n",
      "2023-03-29 18:12:35 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:35 INFO: Loading: ner\n",
      "2023-03-29 18:12:35 INFO: Done loading processors!\n",
      "2023-03-29 18:12:37 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:37 INFO: Using device: cpu\n",
      "2023-03-29 18:12:37 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:37 INFO: Loading: pos\n",
      "2023-03-29 18:12:37 INFO: Loading: lemma\n",
      "2023-03-29 18:12:37 INFO: Loading: constituency\n",
      "2023-03-29 18:12:38 INFO: Loading: depparse\n",
      "2023-03-29 18:12:38 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:38 INFO: Loading: ner\n",
      "2023-03-29 18:12:39 INFO: Done loading processors!\n",
      "2023-03-29 18:12:41 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:41 INFO: Using device: cpu\n",
      "2023-03-29 18:12:41 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:41 INFO: Loading: pos\n",
      "2023-03-29 18:12:42 INFO: Loading: lemma\n",
      "2023-03-29 18:12:42 INFO: Loading: constituency\n",
      "2023-03-29 18:12:43 INFO: Loading: depparse\n",
      "2023-03-29 18:12:44 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:44 INFO: Loading: ner\n",
      "2023-03-29 18:12:45 INFO: Done loading processors!\n",
      "2023-03-29 18:12:48 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:48 INFO: Using device: cpu\n",
      "2023-03-29 18:12:48 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:48 INFO: Loading: pos\n",
      "2023-03-29 18:12:49 INFO: Loading: lemma\n",
      "2023-03-29 18:12:49 INFO: Loading: constituency\n",
      "2023-03-29 18:12:49 INFO: Loading: depparse\n",
      "2023-03-29 18:12:49 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:50 INFO: Loading: ner\n",
      "2023-03-29 18:12:50 INFO: Done loading processors!\n",
      "2023-03-29 18:12:51 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:51 INFO: Using device: cpu\n",
      "2023-03-29 18:12:51 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:51 INFO: Loading: pos\n",
      "2023-03-29 18:12:51 INFO: Loading: lemma\n",
      "2023-03-29 18:12:51 INFO: Loading: constituency\n",
      "2023-03-29 18:12:52 INFO: Loading: depparse\n",
      "2023-03-29 18:12:52 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:52 INFO: Loading: ner\n",
      "2023-03-29 18:12:53 INFO: Done loading processors!\n",
      "2023-03-29 18:12:54 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:54 INFO: Using device: cpu\n",
      "2023-03-29 18:12:54 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:54 INFO: Loading: pos\n",
      "2023-03-29 18:12:54 INFO: Loading: lemma\n",
      "2023-03-29 18:12:54 INFO: Loading: constituency\n",
      "2023-03-29 18:12:54 INFO: Loading: depparse\n",
      "2023-03-29 18:12:55 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:55 INFO: Loading: ner\n",
      "2023-03-29 18:12:55 INFO: Done loading processors!\n",
      "2023-03-29 18:12:57 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:12:57 INFO: Using device: cpu\n",
      "2023-03-29 18:12:57 INFO: Loading: tokenize\n",
      "2023-03-29 18:12:57 INFO: Loading: pos\n",
      "2023-03-29 18:12:58 INFO: Loading: lemma\n",
      "2023-03-29 18:12:58 INFO: Loading: constituency\n",
      "2023-03-29 18:12:58 INFO: Loading: depparse\n",
      "2023-03-29 18:12:58 INFO: Loading: sentiment\n",
      "2023-03-29 18:12:59 INFO: Loading: ner\n",
      "2023-03-29 18:12:59 INFO: Done loading processors!\n",
      "2023-03-29 18:13:01 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:01 INFO: Using device: cpu\n",
      "2023-03-29 18:13:01 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:01 INFO: Loading: pos\n",
      "2023-03-29 18:13:02 INFO: Loading: lemma\n",
      "2023-03-29 18:13:02 INFO: Loading: constituency\n",
      "2023-03-29 18:13:03 INFO: Loading: depparse\n",
      "2023-03-29 18:13:04 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:05 INFO: Loading: ner\n",
      "2023-03-29 18:13:06 INFO: Done loading processors!\n",
      "2023-03-29 18:13:09 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:09 INFO: Using device: cpu\n",
      "2023-03-29 18:13:09 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:09 INFO: Loading: pos\n",
      "2023-03-29 18:13:09 INFO: Loading: lemma\n",
      "2023-03-29 18:13:09 INFO: Loading: constituency\n",
      "2023-03-29 18:13:09 INFO: Loading: depparse\n",
      "2023-03-29 18:13:09 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:10 INFO: Loading: ner\n",
      "2023-03-29 18:13:10 INFO: Done loading processors!\n",
      "2023-03-29 18:13:11 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:11 INFO: Using device: cpu\n",
      "2023-03-29 18:13:11 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:11 INFO: Loading: pos\n",
      "2023-03-29 18:13:12 INFO: Loading: lemma\n",
      "2023-03-29 18:13:12 INFO: Loading: constituency\n",
      "2023-03-29 18:13:12 INFO: Loading: depparse\n",
      "2023-03-29 18:13:12 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:12 INFO: Loading: ner\n",
      "2023-03-29 18:13:13 INFO: Done loading processors!\n",
      "2023-03-29 18:13:14 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:14 INFO: Using device: cpu\n",
      "2023-03-29 18:13:14 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:14 INFO: Loading: pos\n",
      "2023-03-29 18:13:14 INFO: Loading: lemma\n",
      "2023-03-29 18:13:14 INFO: Loading: constituency\n",
      "2023-03-29 18:13:15 INFO: Loading: depparse\n",
      "2023-03-29 18:13:15 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:15 INFO: Loading: ner\n",
      "2023-03-29 18:13:16 INFO: Done loading processors!\n",
      "2023-03-29 18:13:18 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:18 INFO: Using device: cpu\n",
      "2023-03-29 18:13:18 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:18 INFO: Loading: pos\n",
      "2023-03-29 18:13:18 INFO: Loading: lemma\n",
      "2023-03-29 18:13:18 INFO: Loading: constituency\n",
      "2023-03-29 18:13:19 INFO: Loading: depparse\n",
      "2023-03-29 18:13:19 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:20 INFO: Loading: ner\n",
      "2023-03-29 18:13:21 INFO: Done loading processors!\n",
      "2023-03-29 18:13:25 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:25 INFO: Using device: cpu\n",
      "2023-03-29 18:13:25 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:25 INFO: Loading: pos\n",
      "2023-03-29 18:13:25 INFO: Loading: lemma\n",
      "2023-03-29 18:13:25 INFO: Loading: constituency\n",
      "2023-03-29 18:13:25 INFO: Loading: depparse\n",
      "2023-03-29 18:13:25 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:26 INFO: Loading: ner\n",
      "2023-03-29 18:13:26 INFO: Done loading processors!\n",
      "2023-03-29 18:13:28 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:28 INFO: Using device: cpu\n",
      "2023-03-29 18:13:28 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:28 INFO: Loading: pos\n",
      "2023-03-29 18:13:29 INFO: Loading: lemma\n",
      "2023-03-29 18:13:29 INFO: Loading: constituency\n",
      "2023-03-29 18:13:29 INFO: Loading: depparse\n",
      "2023-03-29 18:13:29 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:29 INFO: Loading: ner\n",
      "2023-03-29 18:13:30 INFO: Done loading processors!\n",
      "2023-03-29 18:13:32 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:32 INFO: Using device: cpu\n",
      "2023-03-29 18:13:32 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:32 INFO: Loading: pos\n",
      "2023-03-29 18:13:33 INFO: Loading: lemma\n",
      "2023-03-29 18:13:33 INFO: Loading: constituency\n",
      "2023-03-29 18:13:33 INFO: Loading: depparse\n",
      "2023-03-29 18:13:33 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:34 INFO: Loading: ner\n",
      "2023-03-29 18:13:34 INFO: Done loading processors!\n",
      "2023-03-29 18:13:36 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:36 INFO: Using device: cpu\n",
      "2023-03-29 18:13:36 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:36 INFO: Loading: pos\n",
      "2023-03-29 18:13:36 INFO: Loading: lemma\n",
      "2023-03-29 18:13:36 INFO: Loading: constituency\n",
      "2023-03-29 18:13:37 INFO: Loading: depparse\n",
      "2023-03-29 18:13:37 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:38 INFO: Loading: ner\n",
      "2023-03-29 18:13:39 INFO: Done loading processors!\n",
      "2023-03-29 18:13:41 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:41 INFO: Using device: cpu\n",
      "2023-03-29 18:13:41 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:41 INFO: Loading: pos\n",
      "2023-03-29 18:13:42 INFO: Loading: lemma\n",
      "2023-03-29 18:13:42 INFO: Loading: constituency\n",
      "2023-03-29 18:13:43 INFO: Loading: depparse\n",
      "2023-03-29 18:13:44 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:45 INFO: Loading: ner\n",
      "2023-03-29 18:13:46 INFO: Done loading processors!\n",
      "2023-03-29 18:13:53 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:53 INFO: Using device: cpu\n",
      "2023-03-29 18:13:53 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:53 INFO: Loading: pos\n",
      "2023-03-29 18:13:53 INFO: Loading: lemma\n",
      "2023-03-29 18:13:54 INFO: Loading: constituency\n",
      "2023-03-29 18:13:54 INFO: Loading: depparse\n",
      "2023-03-29 18:13:54 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:55 INFO: Loading: ner\n",
      "2023-03-29 18:13:55 INFO: Done loading processors!\n",
      "2023-03-29 18:13:56 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:13:56 INFO: Using device: cpu\n",
      "2023-03-29 18:13:56 INFO: Loading: tokenize\n",
      "2023-03-29 18:13:56 INFO: Loading: pos\n",
      "2023-03-29 18:13:56 INFO: Loading: lemma\n",
      "2023-03-29 18:13:56 INFO: Loading: constituency\n",
      "2023-03-29 18:13:57 INFO: Loading: depparse\n",
      "2023-03-29 18:13:57 INFO: Loading: sentiment\n",
      "2023-03-29 18:13:57 INFO: Loading: ner\n",
      "2023-03-29 18:13:58 INFO: Done loading processors!\n",
      "2023-03-29 18:14:01 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:01 INFO: Using device: cpu\n",
      "2023-03-29 18:14:01 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:01 INFO: Loading: pos\n",
      "2023-03-29 18:14:01 INFO: Loading: lemma\n",
      "2023-03-29 18:14:01 INFO: Loading: constituency\n",
      "2023-03-29 18:14:02 INFO: Loading: depparse\n",
      "2023-03-29 18:14:02 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:02 INFO: Loading: ner\n",
      "2023-03-29 18:14:03 INFO: Done loading processors!\n",
      "2023-03-29 18:14:09 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:09 INFO: Using device: cpu\n",
      "2023-03-29 18:14:09 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:09 INFO: Loading: pos\n",
      "2023-03-29 18:14:10 INFO: Loading: lemma\n",
      "2023-03-29 18:14:10 INFO: Loading: constituency\n",
      "2023-03-29 18:14:11 INFO: Loading: depparse\n",
      "2023-03-29 18:14:11 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:13 INFO: Loading: ner\n",
      "2023-03-29 18:14:14 INFO: Done loading processors!\n",
      "2023-03-29 18:14:20 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:20 INFO: Using device: cpu\n",
      "2023-03-29 18:14:20 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:20 INFO: Loading: pos\n",
      "2023-03-29 18:14:20 INFO: Loading: lemma\n",
      "2023-03-29 18:14:20 INFO: Loading: constituency\n",
      "2023-03-29 18:14:21 INFO: Loading: depparse\n",
      "2023-03-29 18:14:22 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:22 INFO: Loading: ner\n",
      "2023-03-29 18:14:23 INFO: Done loading processors!\n",
      "2023-03-29 18:14:26 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:26 INFO: Using device: cpu\n",
      "2023-03-29 18:14:26 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:26 INFO: Loading: pos\n",
      "2023-03-29 18:14:26 INFO: Loading: lemma\n",
      "2023-03-29 18:14:26 INFO: Loading: constituency\n",
      "2023-03-29 18:14:26 INFO: Loading: depparse\n",
      "2023-03-29 18:14:26 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:27 INFO: Loading: ner\n",
      "2023-03-29 18:14:27 INFO: Done loading processors!\n",
      "2023-03-29 18:14:31 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:31 INFO: Using device: cpu\n",
      "2023-03-29 18:14:31 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:31 INFO: Loading: pos\n",
      "2023-03-29 18:14:32 INFO: Loading: lemma\n",
      "2023-03-29 18:14:32 INFO: Loading: constituency\n",
      "2023-03-29 18:14:32 INFO: Loading: depparse\n",
      "2023-03-29 18:14:33 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:33 INFO: Loading: ner\n",
      "2023-03-29 18:14:34 INFO: Done loading processors!\n",
      "2023-03-29 18:14:36 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:36 INFO: Using device: cpu\n",
      "2023-03-29 18:14:36 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:36 INFO: Loading: pos\n",
      "2023-03-29 18:14:37 INFO: Loading: lemma\n",
      "2023-03-29 18:14:37 INFO: Loading: constituency\n",
      "2023-03-29 18:14:38 INFO: Loading: depparse\n",
      "2023-03-29 18:14:39 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:40 INFO: Loading: ner\n",
      "2023-03-29 18:14:41 INFO: Done loading processors!\n",
      "2023-03-29 18:14:43 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:43 INFO: Using device: cpu\n",
      "2023-03-29 18:14:43 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:43 INFO: Loading: pos\n",
      "2023-03-29 18:14:44 INFO: Loading: lemma\n",
      "2023-03-29 18:14:44 INFO: Loading: constituency\n",
      "2023-03-29 18:14:45 INFO: Loading: depparse\n",
      "2023-03-29 18:14:46 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:47 INFO: Loading: ner\n",
      "2023-03-29 18:14:48 INFO: Done loading processors!\n",
      "2023-03-29 18:14:54 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:54 INFO: Using device: cpu\n",
      "2023-03-29 18:14:54 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:54 INFO: Loading: pos\n",
      "2023-03-29 18:14:54 INFO: Loading: lemma\n",
      "2023-03-29 18:14:54 INFO: Loading: constituency\n",
      "2023-03-29 18:14:55 INFO: Loading: depparse\n",
      "2023-03-29 18:14:55 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:55 INFO: Loading: ner\n",
      "2023-03-29 18:14:56 INFO: Done loading processors!\n",
      "2023-03-29 18:14:57 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:14:57 INFO: Using device: cpu\n",
      "2023-03-29 18:14:57 INFO: Loading: tokenize\n",
      "2023-03-29 18:14:57 INFO: Loading: pos\n",
      "2023-03-29 18:14:58 INFO: Loading: lemma\n",
      "2023-03-29 18:14:58 INFO: Loading: constituency\n",
      "2023-03-29 18:14:58 INFO: Loading: depparse\n",
      "2023-03-29 18:14:58 INFO: Loading: sentiment\n",
      "2023-03-29 18:14:59 INFO: Loading: ner\n",
      "2023-03-29 18:14:59 INFO: Done loading processors!\n",
      "2023-03-29 18:15:02 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:15:02 INFO: Using device: cpu\n",
      "2023-03-29 18:15:02 INFO: Loading: tokenize\n",
      "2023-03-29 18:15:02 INFO: Loading: pos\n",
      "2023-03-29 18:15:02 INFO: Loading: lemma\n",
      "2023-03-29 18:15:02 INFO: Loading: constituency\n",
      "2023-03-29 18:15:03 INFO: Loading: depparse\n",
      "2023-03-29 18:15:03 INFO: Loading: sentiment\n",
      "2023-03-29 18:15:03 INFO: Loading: ner\n",
      "2023-03-29 18:15:04 INFO: Done loading processors!\n",
      "2023-03-29 18:15:05 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:15:05 INFO: Using device: cpu\n",
      "2023-03-29 18:15:05 INFO: Loading: tokenize\n",
      "2023-03-29 18:15:05 INFO: Loading: pos\n",
      "2023-03-29 18:15:05 INFO: Loading: lemma\n",
      "2023-03-29 18:15:05 INFO: Loading: constituency\n",
      "2023-03-29 18:15:06 INFO: Loading: depparse\n",
      "2023-03-29 18:15:07 INFO: Loading: sentiment\n",
      "2023-03-29 18:15:07 INFO: Loading: ner\n",
      "2023-03-29 18:15:08 INFO: Done loading processors!\n",
      "2023-03-29 18:15:10 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:15:10 INFO: Using device: cpu\n",
      "2023-03-29 18:15:10 INFO: Loading: tokenize\n",
      "2023-03-29 18:15:10 INFO: Loading: pos\n",
      "2023-03-29 18:15:12 INFO: Loading: lemma\n",
      "2023-03-29 18:15:12 INFO: Loading: constituency\n",
      "2023-03-29 18:15:13 INFO: Loading: depparse\n",
      "2023-03-29 18:15:13 INFO: Loading: sentiment\n",
      "2023-03-29 18:15:13 INFO: Loading: ner\n",
      "2023-03-29 18:15:14 INFO: Done loading processors!\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 1/2 [04:57<04:57, 297.06s/it]2023-03-29 18:15:16 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:15:16 INFO: Using device: cpu\n",
      "2023-03-29 18:15:16 INFO: Loading: tokenize\n",
      "2023-03-29 18:15:16 INFO: Loading: pos\n",
      "2023-03-29 18:15:16 INFO: Loading: lemma\n",
      "2023-03-29 18:15:16 INFO: Loading: constituency\n",
      "2023-03-29 18:15:16 INFO: Loading: depparse\n",
      "2023-03-29 18:15:16 INFO: Loading: sentiment\n",
      "2023-03-29 18:15:17 INFO: Loading: ner\n",
      "2023-03-29 18:15:17 INFO: Done loading processors!\n",
      "2023-03-29 18:15:22 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| constituency | wsj       |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2023-03-29 18:15:22 INFO: Using device: cpu\n",
      "2023-03-29 18:15:22 INFO: Loading: tokenize\n",
      "2023-03-29 18:15:22 INFO: Loading: pos\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 1/2 [05:03<05:03, 303.65s/it]\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/99/81q36jp56hlcz9_60h7px6y40000gn/T/ipykernel_24563/2454438697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfile_sentence_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_trawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#update the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/99/81q36jp56hlcz9_60h7px6y40000gn/T/ipykernel_24563/3167979118.py\u001b[0m in \u001b[0;36mdoc_trawl\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# use ner function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msentence_level_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# any other output we want to add that doesn't rely on the ner tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/99/81q36jp56hlcz9_60h7px6y40000gn/T/ipykernel_24563/1047455754.py\u001b[0m in \u001b[0;36mner\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#Find the Root Subject-verb linkages in the sentences using stanza\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# this sets up a default neural pipeline in English\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, download_method, resources_url, resources_branch, resources_version, proxies, foundation_cache, device, allow_unknown_language, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;31m# try to build processor, throw an exception if there is a requirements issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[0m\u001b[1;32m    297\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                                                                                           device=self.device)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# build the final config for the processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/pipeline/pos_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, pipeline, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 'charlm_backward_file': config.get('backward_charlm_path', None)}\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# set up trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoundation_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoundation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tqdm'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tqdm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/models/pos/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, pretrain, model_file, device, foundation_cache)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# load everything from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoundation_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfoundation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# build model from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/models/pos/trainer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename, pretrain, args, foundation_cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0memb_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pretrain'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpretrain\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# we use pretrain only if args['pretrain'] == True and pretrain is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0memb_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_hid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'share_hid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoundation_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfoundation_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/models/common/pretrain.py\u001b[0m in \u001b[0;36memb\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_emb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stanza/models/common/pretrain.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded pretrain from {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'emb'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'vocab'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "file_sentence_dict = {}\n",
    "files = glob.glob(\"inputs/*\") #get all the files in the inputs folder\n",
    "\n",
    "for file in tqdm(files,total=len(files)):\n",
    "    file_sentence_dict.update({file: doc_trawl(file)}) #update the dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca1bf-861d-4c6d-b3c2-590d77ffae3d",
   "metadata": {},
   "source": [
    "## IV. Unpacking that into DF\n",
    "\n",
    "Dataframe with \n",
    "- index is filename-sentence\n",
    "- columns are sentence level variables\n",
    "\n",
    "Now we can do diagnostics, examine the output, and use it faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5dc68-6471-40f9-95c1-34520164ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_tri_level_dict(a_dict):\n",
    "    df = pd.concat(map(lambda x: pd.DataFrame.from_dict(x).T, a_dict.values()), keys=a_dict.keys())\n",
    "    df.index = df.index.rename(['file','sentence'])\n",
    "    return df\n",
    "\n",
    "unpack_tri_level_dict(file_sentence_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
