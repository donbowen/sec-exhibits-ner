{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f79adb0-80f0-4cbf-b694-2277fca5c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f430c818-2afe-4393-b628-11a7ade4ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(sentence): \n",
    "    \n",
    "    words = nltk.word_tokenize(sentence) #break down the sentence into words\n",
    "    tagged = nltk.pos_tag(words) #tag the words with Part of Speech \n",
    "    chunks = nltk.ne_chunk(tagged, binary=False) #binary = False named entities are classified (i.e PERSON, ORGANIZATION)\n",
    "    \n",
    "    entities = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'label'): #hasattr(obj, key) -- checking if chunks have a label or not \n",
    "              entities.append(' '.join(c[0] for c in chunk)) #append entities to array\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8615c-6482-4a67-80dc-8d7c89be2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "filename = 'inputs/temp.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6c8b2-e75c-40b6-b979-7c75d5eaf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(filename, \"r\")\n",
    "raw_text_file = fp.read() #read in the raw text file\n",
    "    \n",
    "raw_sentences = nltk.sent_tokenize(raw_text_file) #break text file into indiv sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff1c1d-4e94-45ae-96db-3f29bf8b43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_sentences = ['Python is an interpreted, high-level and general-purpose programming language', \n",
    "#                 'Apple acquired Zoom in China on Wednesday 6th, May 2020. This news has made Apple and Google stock jump by 5% on Dow Jones in the United States of America',     \n",
    "#                 'Pythons design philosophy emphasizes code readability with on Feb 13 during the Revolutionary War']\n",
    "\n",
    "all_combined_list = []\n",
    "\n",
    "for sentence in raw_sentences:\n",
    "      \n",
    "    #Get the entities of the sentence using the NER function above \n",
    "    entities = ner(sentence) \n",
    "    \n",
    "    #Combine the sentence and entities into one array (get the final value for the dict)\n",
    "    combined = [sentence, entities]     \n",
    "    \n",
    "    all_combined_list.append(combined) \n",
    "    \n",
    "    final_dict.update({filename:all_combined_list})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0afc93-5a34-47ef-94b8-37ca14b58fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6637ed7-e44c-4681-8a28-4eaa0efe5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58883570-d86e-417a-83f6-e44e0d012c07",
   "metadata": {},
   "source": [
    "## Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbc6d6a-29f5-46db-8d7c-f75bf904b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combined_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6d75332-8884-447d-a410-a45061fcd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_trawl(filename):\n",
    "    \n",
    "    all_combined_list = []\n",
    "    # all_combined_list.clear() \n",
    "    \n",
    "    #open file, get raw text file, break into sentences, get raw sentences\n",
    "    fp = open(filename, \"r\")\n",
    "    raw_text_file = fp.read() #read in the raw text file\n",
    "    \n",
    "    raw_sentences = nltk.sent_tokenize(raw_text_file) #break text file into indiv sentences\n",
    "    \n",
    "    \n",
    "    #traverse thru sentences\n",
    "    for sentence in raw_sentences:\n",
    "        \n",
    "        #Get the entities of the sentence using the NER function above \n",
    "        entities = ner(sentence)\n",
    "        \n",
    "        #Combine the sentence and entities into one array (get the final value for the dict)\n",
    "        combined = [sentence, entities]  \n",
    "    \n",
    "        all_combined_list.append(combined)\n",
    "        \n",
    "        #final_dict.update({filename:all_combined_list})\n",
    "        \n",
    "    return all_combined_list \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "371a2329-e163-4d5d-9e63-8bc10f7f12c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs_temp/temp.txt': [['Python is an interpreted, high-level and general-purpose programming language.', ['Python']], ['Apple acquired Zoom in China on Wednesday 6th, May 2020.', ['Apple', 'Zoom', 'China']], ['This news has made Apple and Google stock jump by 5% on Dow Jones in the United States of America and pythons design philosophy emphasizes code readability with on Feb 13 during the Revolutionary War.', ['Apple', 'Google', 'Dow Jones', 'United States', 'America']]], 'inputs_temp/temp2.txt': [['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.', []], ['The writer has no idea what topic the random paragraph will be about when it appears.', []], ['This forces the writer to use creativity to complete one of three common writing challenges.', []], ['The writer can use the paragraph as the first one of a short story and build upon it.', []], ['A second option is to use the random paragraph somewhere in a short story they create.', []], ['The third option is to have the random paragraph be the ending paragraph in a short story.', []], ['No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.', []]]}\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"inputs_temp/*\")\n",
    "temp = {}\n",
    "\n",
    "for file in files:\n",
    "    x = doc_trawl(file)\n",
    "    temp.update({file: x})\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c79ef9a-b7ca-4246-a4ba-1b0a9756c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_temp/temp.txt\n",
      "\n",
      "{'inputs_temp/temp.txt': [['Python is an interpreted, high-level and general-purpose programming language.', ['Python']], ['Apple acquired Zoom in China on Wednesday 6th, May 2020.', ['Apple', 'Zoom', 'China']], ['This news has made Apple and Google stock jump by 5% on Dow Jones in the United States of America and pythons design philosophy emphasizes code readability with on Feb 13 during the Revolutionary War.', ['Apple', 'Google', 'Dow Jones', 'United States', 'America']]]}\n",
      "inputs_temp/temp2.txt\n",
      "\n",
      "{'inputs_temp/temp.txt': [['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.', []], ['The writer has no idea what topic the random paragraph will be about when it appears.', []], ['This forces the writer to use creativity to complete one of three common writing challenges.', []], ['The writer can use the paragraph as the first one of a short story and build upon it.', []], ['A second option is to use the random paragraph somewhere in a short story they create.', []], ['The third option is to have the random paragraph be the ending paragraph in a short story.', []], ['No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.', []]], 'inputs_temp/temp2.txt': [['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.', []], ['The writer has no idea what topic the random paragraph will be about when it appears.', []], ['This forces the writer to use creativity to complete one of three common writing challenges.', []], ['The writer can use the paragraph as the first one of a short story and build upon it.', []], ['A second option is to use the random paragraph somewhere in a short story they create.', []], ['The third option is to have the random paragraph be the ending paragraph in a short story.', []], ['No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.', []]]}\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"inputs_temp/*\")\n",
    "doc_ner_output = {}\n",
    "\n",
    "for file in files:\n",
    "    #tobey = doc_trawl(file)\n",
    "    print(file)\n",
    "    print(\"\")\n",
    "    doc_ner_output[file] = doc_trawl(file)\n",
    "    print(doc_ner_output)\n",
    "    \n",
    "    #print(file,tobey)\n",
    "    #print(\"\")\n",
    "    #print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a74c4b-3a2b-4f16-9adc-bbb97d4433de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs_temp/temp.txt': [['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.',\n",
       "   []],\n",
       "  ['The writer has no idea what topic the random paragraph will be about when it appears.',\n",
       "   []],\n",
       "  ['This forces the writer to use creativity to complete one of three common writing challenges.',\n",
       "   []],\n",
       "  ['The writer can use the paragraph as the first one of a short story and build upon it.',\n",
       "   []],\n",
       "  ['A second option is to use the random paragraph somewhere in a short story they create.',\n",
       "   []],\n",
       "  ['The third option is to have the random paragraph be the ending paragraph in a short story.',\n",
       "   []],\n",
       "  ['No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.',\n",
       "   []]],\n",
       " 'inputs_temp/temp2.txt': [['Generating random paragraphs can be an excellent way for writers to get their creative flow going at the beginning of the day.',\n",
       "   []],\n",
       "  ['The writer has no idea what topic the random paragraph will be about when it appears.',\n",
       "   []],\n",
       "  ['This forces the writer to use creativity to complete one of three common writing challenges.',\n",
       "   []],\n",
       "  ['The writer can use the paragraph as the first one of a short story and build upon it.',\n",
       "   []],\n",
       "  ['A second option is to use the random paragraph somewhere in a short story they create.',\n",
       "   []],\n",
       "  ['The third option is to have the random paragraph be the ending paragraph in a short story.',\n",
       "   []],\n",
       "  ['No matter which of these challenges is undertaken, the writer is forced to use creativity to incorporate the paragraph into their writing.',\n",
       "   []]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04357e-9646-4c27-ad0a-2997b7c0f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"inputs_temp/*\")\n",
    "doc_ner_output = {}\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    doc_ner_output[file] = doc_trawl(file)\n",
    "\n",
    "doc_ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bf932-36e1-4f6a-a466-a6be2d59d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(\"inputs_temp/*\")\n",
    "#doc_ner_output = {}\n",
    "\n",
    "#for file in tqdm(files):\n",
    "#    doc_ner_output[file] = doc_trawl(file)\n",
    "\n",
    "#doc_ner_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
